{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336362/2495212192.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/data/ephemeral/home/level2-cv-semanticsegmentation-cv-13/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# python native\n",
    "import os\n",
    "\n",
    "# external library\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.registry import DATASETS, TRANSFORMS, MODELS, METRICS\n",
    "from mmseg.datasets import BaseSegDataset\n",
    "from mmseg.models.segmentors import EncoderDecoder\n",
    "from mmseg.models.decode_heads import ASPPHead, FCNHead, SegformerHead \n",
    "from mmseg.models.utils.wrappers import resize\n",
    "\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.dataset import Compose\n",
    "from mmengine.runner import Runner, load_checkpoint\n",
    "from mmengine.evaluator import BaseMetric\n",
    "from mmengine.logging import MMLogger, print_log\n",
    "from mmengine.structures import PixelData\n",
    "\n",
    "from mmcv.transforms import BaseTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROOT = \"/data/ephemeral/home/level2-cv-semanticsegmentation-cv-13/data/test/DCM\" # 이미지 데이터 경로설정\n",
    "SAVE_DIR = \"/data/ephemeral/home/level2-cv-semanticsegmentation-cv-13/model/uper\" # CSV파일 저장 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../model/uper/iter_19200.pth\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import init_model\n",
    "\n",
    "config_path = 'configs/_teamconfig_/upernet/config.py'\n",
    "checkpoint_path = '../model/uper/iter_19200.pth'\n",
    "\n",
    "cfg = Config.fromfile(config_path)\n",
    "cfg.launcher = \"none\"\n",
    "cfg.work_dir = os.path.join('../predictions', \"upernet\")\n",
    "\n",
    "# init model and load checkpoint\n",
    "model = init_model(config_path, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]\n",
    "\n",
    "CLASS2IND = {v: i for i, v in enumerate(CLASSES)}\n",
    "IND2CLASS = {v: k for k, v in CLASS2IND.items()}\n",
    "\n",
    "def _preprare_data(imgs, model):\n",
    "\n",
    "    pipeline = Compose([\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            # dict(type='Resize', scale=(1450, 1450)),\n",
    "            # dict(type='LoadXRayAnnotations'),\n",
    "            # dict(type='TransposeAnnotations'),\n",
    "            dict(type='PackSegInputs')\n",
    "        ])\n",
    "            \n",
    "    is_batch = True\n",
    "    if not isinstance(imgs, (list, tuple)):\n",
    "        imgs = [imgs]\n",
    "        is_batch = False\n",
    "\n",
    "    if isinstance(imgs[0], np.ndarray):\n",
    "        cfg.test_pipeline[0]['type'] = 'LoadImageFromNDArray'\n",
    "\n",
    "    # TODO: Consider using the singleton pattern to avoid building\n",
    "    # a pipeline for each inference\n",
    "\n",
    "    data = defaultdict(list)\n",
    "    for img in imgs:\n",
    "        if isinstance(img, np.ndarray):\n",
    "            data_ = dict(img=img)\n",
    "        else:\n",
    "            data_ = dict(img_path=img)\n",
    "        data_ = pipeline(data_)\n",
    "        data['inputs'].append(data_['inputs'])\n",
    "        data['data_samples'].append(data_['data_samples'])\n",
    "\n",
    "    return data, is_batch\n",
    "\n",
    "# define colors\n",
    "PALETTE = [\n",
    "    (220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230), (106, 0, 228),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 70), (0, 0, 192), (250, 170, 30),\n",
    "    (100, 170, 30), (220, 220, 0), (175, 116, 175), (250, 0, 30), (165, 42, 42),\n",
    "    (255, 77, 255), (0, 226, 252), (182, 182, 255), (0, 82, 0), (120, 166, 157),\n",
    "    (110, 76, 0), (174, 57, 255), (199, 100, 0), (72, 0, 118), (255, 179, 240),\n",
    "    (0, 125, 92), (209, 0, 151), (188, 208, 182), (0, 220, 176),\n",
    "]\n",
    "\n",
    "# utility function\n",
    "# this does not care overlap\n",
    "def label2rgb(label):\n",
    "    image_size = label.shape[1:] + (3, )\n",
    "    image = np.zeros(image_size, dtype=np.uint8)\n",
    "    \n",
    "    for i, class_label in enumerate(label):\n",
    "        image[class_label == 1] = PALETTE[i]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pngs = {\n",
    "    os.path.relpath(os.path.join(root, fname), start=IMAGE_ROOT)\n",
    "    for root, _dirs, files in os.walk(IMAGE_ROOT)\n",
    "    for fname in files\n",
    "    if os.path.splitext(fname)[1].lower() == \".png\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayInferenceDataset(Dataset):\n",
    "    def __init__(self, transforms=None):\n",
    "        _filenames = pngs\n",
    "        _filenames = np.array(sorted(_filenames))\n",
    "        \n",
    "        self.filenames = _filenames\n",
    "        # self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image_name = self.filenames[item]\n",
    "        image_path = os.path.join(IMAGE_ROOT, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "            \n",
    "        return image, image_name , image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mask_to_rle(mask):\n",
    "    '''\n",
    "    mask: numpy array binary mask \n",
    "    1 - mask \n",
    "    0 - background\n",
    "    Returns encoded run length \n",
    "    '''\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def decode_rle_to_mask(rle, height, width):\n",
    "    s = rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(height * width, dtype=np.uint8)\n",
    "    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    \n",
    "    return img.reshape(height, width)\n",
    "\n",
    "def test(model, data_loader, thr=0.5):\n",
    "    rles = []\n",
    "    filename_and_class = []\n",
    "    with torch.no_grad():\n",
    "        n_class = len(CLASSES)\n",
    "\n",
    "        for step, (images, image_names, image_path) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            # images = images.cuda()    \n",
    "            images = image_path\n",
    "            data, is_batch = _preprare_data(images, model)\n",
    "            results = model.test_step(data)\n",
    "            results = results[0].pred_sem_seg.data\n",
    "            results = (results > thr).detach().cpu().numpy()\n",
    "            results = results.astype(np.uint8)\n",
    "            results = results.reshape(1,29,2048,2048)\n",
    "            # print(results.shape)\n",
    "            \n",
    "            for output, image_name in zip(results, image_names):\n",
    "                for c, segm in enumerate(output):\n",
    "                    rle = encode_mask_to_rle(segm)\n",
    "                    rles.append(rle)\n",
    "                    filename_and_class.append(f\"{IND2CLASS[c]}_{image_name}\")\n",
    "                    \n",
    "    return rles, filename_and_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = XRayInferenceDataset(transforms=None)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [07:48<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "rles, filename_and_class = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, filename = zip(*[x.split(\"_\") for x in filename_and_class])\n",
    "\n",
    "image_name = [os.path.basename(f) for f in filename]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"image_name\": image_name,\n",
    "        \"class\": classes,\n",
    "        \"rle\": rles,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.to_csv(os.path.join(SAVE_DIR, \"output.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
